{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a0836e",
   "metadata": {},
   "source": [
    "# Sheet 04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462c2fc",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c6c28",
   "metadata": {},
   "source": [
    "Autors: Marten Ringwelski, Nico Ostermann, Simon Liessem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbbd45",
   "metadata": {},
   "source": [
    "Note that this notebook MUST be executed in order to get everything to work.\n",
    "The tasks can't be run individually. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab973fc",
   "metadata": {},
   "source": [
    "Also eCampus does not allow for uploading nested directory structures which makes it hard to properly organize the files. The files are expected to be in the `data` directory which itself is placed next to this notebook.\n",
    "\n",
    "If you extract the zip file we handed in everything should work just fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b476f10",
   "metadata": {},
   "source": [
    "Autoformatting if `jupyter-black` is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6501019",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import black\n",
    "    import jupyter_black\n",
    "\n",
    "    jupyter_black.load(\n",
    "        lab=False,\n",
    "        line_length=79,\n",
    "        verbosity=\"DEBUG\",\n",
    "        target_version=black.TargetVersion.PY310,\n",
    "    )\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc11336",
   "metadata": {},
   "source": [
    "Import all we weed and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7116a0c",
   "metadata": {},
   "source": [
    "Set seaborn default theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05877eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "import math as m\n",
    "import plotly.express as px\n",
    "import sklearn.manifold\n",
    "import sklearn.discriminant_analysis\n",
    "import scipy as sp\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049365eb",
   "metadata": {},
   "source": [
    "Set seaborn default theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702c2e1",
   "metadata": {},
   "source": [
    "If needed tweak parameters of matplotlib.\n",
    "Here we increase the size and dpi to bet a bigger but still high-res image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64dba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 200\n",
    "mpl.rcParams[\"figure.figsize\"] = (20, 15)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a21f26a",
   "metadata": {},
   "source": [
    "Disable future warnings as we get a lot of them and don't really care for this sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5009ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc9c0f0",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9770e",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f5e7a",
   "metadata": {},
   "source": [
    "Read the dataframe and replace missing values by the respective mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff47bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/breast-cancer-wisconsin.xlsx\")\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "df[\"class\"] = df[\"class\"].map({2: \"benign\", 4: \"malignant\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4552b32",
   "metadata": {},
   "source": [
    "Now define the DataFrame for t-SNE and create a new one with the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns = df.columns.difference([\"class\", \"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d21bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wo_meta = df[data_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d996be",
   "metadata": {},
   "source": [
    "Do t-SNE with different perplexities as the task asked us to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = [5, 10, 20, 30, 40, 50]\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=m.ceil(len(perplexities) / 2),\n",
    ")\n",
    "for perplexity, ax in zip(perplexities, axs.flatten()):\n",
    "    tsne = sk.manifold.TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=perplexity,\n",
    "        init=\"random\",\n",
    "        learning_rate=\"auto\",\n",
    "    )\n",
    "\n",
    "    df_tsne = pd.DataFrame(\n",
    "        tsne.fit_transform(df_wo_meta),\n",
    "        columns=[\"x-tsne\", \"y-tsne\"],\n",
    "        index=df.index,\n",
    "    )\n",
    "    df_tsne[df.columns] = df\n",
    "\n",
    "    ax.set_title(f\"Perplexity: {perplexity}\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    sns.scatterplot(\n",
    "        data=df_tsne,\n",
    "        x=\"x-tsne\",\n",
    "        y=\"y-tsne\",\n",
    "        hue=\"class\",\n",
    "        ax=ax,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47ce02",
   "metadata": {},
   "source": [
    "Copy paste from above but init=\"pca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570abb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = [5, 10, 20, 30, 40, 50]\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=m.ceil(len(perplexities) / 2),\n",
    ")\n",
    "for perplexity, ax in zip(perplexities, axs.flatten()):\n",
    "    tsne = sk.manifold.TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=perplexity,\n",
    "        init=\"pca\",\n",
    "        learning_rate=\"auto\",\n",
    "    )\n",
    "\n",
    "    df_tsne = pd.DataFrame(\n",
    "        tsne.fit_transform(df_wo_meta),\n",
    "        columns=[\"x-tsne\", \"y-tsne\"],\n",
    "        index=df.index,\n",
    "    )\n",
    "    df_tsne[df.columns] = df\n",
    "\n",
    "    ax.set_title(f\"Perplexity: {perplexity}\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    sns.scatterplot(\n",
    "        data=df_tsne,\n",
    "        x=\"x-tsne\",\n",
    "        y=\"y-tsne\",\n",
    "        hue=\"class\",\n",
    "        ax=ax,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cafd604",
   "metadata": {},
   "source": [
    "We see that with a higher perplexity the classes become linearly separable.\n",
    "Also the classes become more dense.\n",
    "\n",
    "We see a slight difference between random and pca initialisation.\n",
    "With PCA initialisation and a perplexity of 10 the classes are slightly more dense than with random initialisation.\n",
    "It makes sense that PCA initialisation is slightly better because they contain more information about the real data than random points.\n",
    "\n",
    "Overall for perplexities greater euqal 20 the classes are nicely separated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dcce49",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5711341f",
   "metadata": {},
   "source": [
    "Read data and use mean for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"data/Data_Cortex_Nuclear.xls\",\n",
    "    index_col=\"MouseID\",\n",
    ")\n",
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf7de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_columns = [\"Genotype\", \"Treatment\", \"Behavior\", \"class\"]\n",
    "df_wo_meta = df[df.columns.difference(meta_columns)]\n",
    "\n",
    "df_scs = df_wo_meta[\n",
    "    np.logical_or(\n",
    "        df[\"class\"] == \"c-SC-s\",\n",
    "        df[\"class\"] == \"t-SC-s\",\n",
    "    )\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5ad835",
   "metadata": {},
   "source": [
    "Now actuall do PCA and create a DataFrame with the result.\n",
    "Also we use equal axis scale for the plot which makes sense since we care about the results from PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af24798",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sk.decomposition.PCA(\n",
    "    n_components=2,\n",
    ")\n",
    "# XXX There must be a better way to do this\n",
    "df_pca = pd.DataFrame(\n",
    "    pca.fit_transform(df_scs),\n",
    "    columns=[\"x-pca\", \"y-pca\"],\n",
    "    index=df_scs.index,\n",
    ")\n",
    "df_pca[df.columns] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c35a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    df_pca,\n",
    "    x=\"x-pca\",\n",
    "    y=\"y-pca\",\n",
    "    hue=\"class\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6454f0",
   "metadata": {},
   "source": [
    "Now we do the same thing but for isomap.\n",
    "As we see by the warnings using 2 or 5 is not good as the resulting graph has more than one connecting component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81613321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't care that the calculation is expensive\n",
    "warnings.simplefilter(\n",
    "    action=\"ignore\",\n",
    "    category=sp.sparse.SparseEfficiencyWarning,\n",
    ")\n",
    "n_neighbors_array = [2, 5, 7, 13, 17, 23, 29]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=m.ceil(len(n_neighbors_array) / 2),\n",
    ")\n",
    "\n",
    "for n_neighbors, ax in zip(n_neighbors_array, axs.flatten()):\n",
    "    isomap = sk.manifold.Isomap(\n",
    "        n_neighbors=n_neighbors,\n",
    "    )\n",
    "\n",
    "    df_isomap = pd.DataFrame(\n",
    "        isomap.fit_transform(df_scs),\n",
    "        columns=[\"x-isomap\", \"y-isomap\"],\n",
    "        index=df_scs.index,\n",
    "    )\n",
    "\n",
    "    df_isomap[df.columns] = df\n",
    "\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "    ax.set_title(f\"n_neighbors: {n_neighbors}\")\n",
    "    sns.scatterplot(\n",
    "        df_isomap,\n",
    "        x=\"x-isomap\",\n",
    "        y=\"y-isomap\",\n",
    "        hue=\"class\",\n",
    "        ax=ax,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f202f",
   "metadata": {},
   "source": [
    "We see that for n_neighbors >=5 the data is nicely separated but one could argue that you can see more than two classes.\n",
    "For n_neighbors >=13 they are nicely separeted in just two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80ddf5",
   "metadata": {},
   "source": [
    "Now we do t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70677141",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = [2, 5, 7, 13, 17, 23, 29, 51]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=m.ceil(len(perplexities) / 2),\n",
    ")\n",
    "\n",
    "for perplexity, ax in zip(perplexities, axs.flatten()):\n",
    "    tsne = sk.manifold.TSNE(\n",
    "        perplexity=perplexity,\n",
    "    )\n",
    "\n",
    "    df_tsne = pd.DataFrame(\n",
    "        tsne.fit_transform(df_scs),\n",
    "        columns=[\"x-tsne\", \"y-tsne\"],\n",
    "        index=df_scs.index,\n",
    "    )\n",
    "\n",
    "    df_tsne[df.columns] = df\n",
    "\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "    ax.set_title(f\"perplexity: {perplexity}\")\n",
    "    sns.scatterplot(\n",
    "        df_tsne,\n",
    "        x=\"x-tsne\",\n",
    "        y=\"y-tsne\",\n",
    "        hue=\"class\",\n",
    "        ax=ax,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be9d5a",
   "metadata": {},
   "source": [
    "We adjusted the perplexity as (according to the scipy docs) it is the only parameter relevant for our purpose.\n",
    "\n",
    "For perplexity >=13 we get similar results to Isomap with n_neighbors>=7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa574e",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d15653",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb148fe",
   "metadata": {},
   "source": [
    "We note that an individual sum element of the sum that defines $S_c$ is a matrix whose columns are all a scaled version of $x_i - x_{mean}$.\n",
    "So overall we need to sum over p Matricies to get p linearly independent columns.\n",
    "This means that we need at least p points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca66f83",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc27231",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/LDA-input.csv\")\n",
    "lda = sk.discriminant_analysis.LinearDiscriminantAnalysis(solver=\"eigen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1122c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lda.fit(\n",
    "    df.drop(columns=\"class\"),\n",
    "    df[\"class\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f5966c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformed_df = pd.DataFrame(\n",
    "    lda.transform(df.drop(columns=\"class\")),\n",
    "    columns=[\"x\", \"y\"],\n",
    ")\n",
    "transformed_df[\"class\"] = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6fb4d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=transformed_df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    hue=\"class\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd389ca6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eeba5f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lda = sk.discriminant_analysis.LinearDiscriminantAnalysis(\n",
    "    solver=\"eigen\",\n",
    "    shrinkage=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9838e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lda.fit(df.drop(columns=\"class\"), df[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d930458",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformed_df = pd.DataFrame(\n",
    "    lda.transform(df.drop(columns=\"class\")),\n",
    "    columns=[\"x\", \"y\"],\n",
    ")\n",
    "transformed_df[\"class\"] = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388274f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=transformed_df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    hue=\"class\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cff6c7",
   "metadata": {},
   "source": [
    "We prefer this plot over the other plot.\n",
    "In the other plot the x-Axis has a huge range so we cannot see differences in the x dimension in a class.\n",
    "This plot has the x axis scaled in another way so we can see even relativly small changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd9958",
   "metadata": {},
   "source": [
    "### d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64dffa0",
   "metadata": {},
   "source": [
    "We observe that the x-axis has a lower range and thus small differences in the x dimension can better be seen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a079b",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589301f6",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee95f84",
   "metadata": {},
   "source": [
    "If the perplexity is the same as the amount of points, the neighborhood scale is set so large that all probablilties are approximatly equal.\n",
    "A large neighborhood scale means a flattened out gauss curve.\n",
    "\n",
    "If all probabilities are equal the KL Divergence is minimized by choosing the distribution Q as uniform distribution for each point y.\n",
    "So the result is as rather a uniformly distributed set of points.\n",
    "\n",
    "If the perplexity is 29 all neighborhood probabilities but one are approximatly equal.\n",
    "The different one is significantly lower than the others.\n",
    "Due to this fact after a lot of steps the classes properly separate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083c0e4",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae33cb",
   "metadata": {},
   "source": [
    "The points at the corners pull their close neighbors strongly and the farther away points weakly.\n",
    "This leads to the small distances.\n",
    "\n",
    "The points in the middle are pulled in all directions euqally strong which results to them staying in the middle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150d85e",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5290a",
   "metadata": {},
   "source": [
    "We do observe that it breaks down into seperate clusters.\n",
    "Since the perplexity is 2 we have a rather high chance that some points distance themselves from the big cluster and form smaller clusters.\n",
    "This happens because if a single point insolates itself, other neighbouring points have a chance to choose the isolated point instead of the bigger cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68642a72",
   "metadata": {},
   "source": [
    "### d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933eb9b",
   "metadata": {},
   "source": [
    "The dataset is a dense circle.\n",
    "With low perplexity points that are actually close together are not seen as close together by tSNE.\n",
    "So a high perplexity is needed to actually connect enough points to recreate the shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad0511",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ae6cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from pprint import pformat\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(namedtuple(\"Node\", \"location left_child right_child\")):\n",
    "    def __repr__(self):\n",
    "        return pformat(self._asdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdtree(points, axis=0):\n",
    "    \"\"\"Given\n",
    "     - a 2D numpy array points, where each column denotes a dimension and each\n",
    "       row a datapoint\n",
    "     - an integer axis indicating the dimension to split at the top level\n",
    "    this recursive function creates and returns a KDTree as it was discussed\n",
    "    in the lecture.\n",
    "    \"\"\"\n",
    "    if points.shape[0] == 0:\n",
    "        return None\n",
    "\n",
    "    k = points.shape[1]  # assumes all points have the same dimension\n",
    "\n",
    "    # Sort point list by axis and choose median as pivot element\n",
    "    points = points[points[:, axis].argsort()]\n",
    "    median = points.shape[0] // 2\n",
    "\n",
    "    # Create node and construct subtrees\n",
    "    return Node(\n",
    "        location=points[median],\n",
    "        left_child=kdtree(points[:median], (axis + 1) % k),\n",
    "        right_child=kdtree(points[median + 1 :], (axis + 1) % k),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ecb42",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05052051",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_NN_rec(tree: Node, query, neighbor=None, axis: int = 0):\n",
    "    \"\"\"\n",
    "    This recursive function accepts\n",
    "     - a KDTree tree\n",
    "     - a query point query\n",
    "     - the axis along which the root node of tree splits\n",
    "     - the current nearest neighbor\n",
    "    The function should return a tuple, which contains the distance\n",
    "    to the query point and the location of the neighbor. For example the\n",
    "    data points np.array([(1, 3), (1, 8), (2, 2), (2, 10), (3, 6), (4, 1), (5,\n",
    "    4), (6, 8), (7, 4), (7, 7), (8, 2), (8, 5), (9, 9)]) should return for a\n",
    "    query point [4,8] the result (2.0, array([6, 8])).\n",
    "    \"\"\"\n",
    "\n",
    "    if not tree:\n",
    "        return None, None\n",
    "\n",
    "    k = tree.location.shape[0]\n",
    "\n",
    "    if query[axis] <= tree.location[axis]:\n",
    "        sub_tree = tree.left_child\n",
    "        other_tree = tree.right_child\n",
    "    else:\n",
    "        sub_tree = tree.right_child\n",
    "        other_tree = tree.left_child\n",
    "\n",
    "    # Get the nearest neighbor from the subtree that our point is in.\n",
    "    # (Downwards pass)\n",
    "    distance, neighbor = one_NN_rec(sub_tree, query, axis=(axis + 1) % k)\n",
    "    if neighbor is None:\n",
    "        neighbor = tree.location\n",
    "        distance = norm(neighbor - query)\n",
    "\n",
    "    # Check if parent is closer than the NN from the subtree\n",
    "    # (Upwards pass)\n",
    "    if norm(tree.location - query) < distance:\n",
    "        neighbor = tree.location\n",
    "        distance = norm(neighbor - query)\n",
    "\n",
    "    # Check if our query could have a neighrest neighbor (which better than our current candidate)\n",
    "    # in the other subtree\n",
    "    if other_tree:\n",
    "        axis_dist = abs(query[axis] - tree.location[axis])\n",
    "        if axis_dist <= distance:\n",
    "            tmpDistance, tmpNeighbor = one_NN_rec(\n",
    "                other_tree, query, axis=(axis + 1) % k\n",
    "            )\n",
    "            if tmpDistance < distance:\n",
    "                distance = tmpDistance\n",
    "                neighbor = tmpNeighbor\n",
    "\n",
    "    return distance, neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b048d",
   "metadata": {},
   "source": [
    "Now execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc260c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = kdtree(\n",
    "    np.array(\n",
    "        [\n",
    "            (1, 3),\n",
    "            (1, 8),\n",
    "            (2, 2),\n",
    "            (2, 10),\n",
    "            (3, 6),\n",
    "            (4, 1),\n",
    "            (5, 4),\n",
    "            (6, 8),\n",
    "            (7, 4),\n",
    "            (7, 7),\n",
    "            (8, 2),\n",
    "            (8, 5),\n",
    "            (9, 9),\n",
    "        ]\n",
    "    ),\n",
    "    0,\n",
    ")\n",
    "n_neighbors = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a86c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_NN_rec(tree, [4, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c02e96c",
   "metadata": {},
   "source": [
    "We see that the distance is 2 and the NN is $(6,8)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd25d2",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf5df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeSecond(elem):\n",
    "    return elem[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_rec(tree, axis, query, neighbors, n_neighbors):\n",
    "    \"\"\"\n",
    "    This recursive function accepts\n",
    "     - a KDTree tree\n",
    "     - the axis along which the root node of tree splits\n",
    "     - a query point query\n",
    "     - a current list of neighbors, sorted with ascending distance\n",
    "       (list of pairs each containing the distance and the point itself)\n",
    "     - the desired number of neighbors n_neighbors\n",
    "    and modifies the neighbors list so that\n",
    "     - points from the tree are added while we have fewer than n_neighbors\n",
    "     - all closer points from the tree replace existing neighbors once weneighbor\n",
    "       reached n_neighbors\n",
    "    It returns the number of nodes that were visited during traversal and modifies\n",
    "    the neighbors-object in-place.\n",
    "    \"\"\"\n",
    "\n",
    "    if not tree:\n",
    "        return 0\n",
    "\n",
    "    k = tree.location.shape[0]\n",
    "\n",
    "    if query[axis] <= tree.location[axis]:\n",
    "        sub_tree = tree.left_child\n",
    "        other_tree = tree.right_child\n",
    "    else:\n",
    "        sub_tree = tree.right_child\n",
    "        other_tree = tree.left_child\n",
    "\n",
    "    # Get the nearest neighbors from the subtree that our point is in.\n",
    "    # (Downwards pass)\n",
    "    travel_count = kNN_rec(\n",
    "        sub_tree, (axis + 1) % k, query, neighbors, n_neighbors\n",
    "    )\n",
    "\n",
    "    # Add the root to the NN list and remove the most distant one\n",
    "    neighbors.append(\n",
    "        (tree.location, norm(tree.location - query)),\n",
    "    )\n",
    "    neighbors.sort(key=takeSecond)\n",
    "    travel_count += 1\n",
    "\n",
    "    if len(neighbors) > n_neighbors:\n",
    "        neighbors.pop(-1)\n",
    "\n",
    "    # Check the other subtree for any better candidates if there could be any\n",
    "    if other_tree:\n",
    "        axis_dist = abs(query[axis] - tree.location[axis])\n",
    "        if axis_dist <= neighbors[-1][1]:\n",
    "            return travel_count + kNN_rec(\n",
    "                other_tree,\n",
    "                (axis + 1) % k,\n",
    "                query,\n",
    "                neighbors,\n",
    "                n_neighbors,\n",
    "            )\n",
    "\n",
    "    return travel_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ab507",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe99fa2",
   "metadata": {},
   "source": [
    "First define the brute force algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0eeb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_force_knn(data, query, n_neighbors):\n",
    "    neighbors_w_dist = []\n",
    "    for point in data:\n",
    "        neighbors_w_dist.append(\n",
    "            (point, norm(point - query)),\n",
    "        )\n",
    "    neighbors_w_dist.sort(key=takeSecond)\n",
    "    neighbors_w_dist = neighbors_w_dist[:n_neighbors]\n",
    "    return neighbors_w_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f054aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random(amount, dim):\n",
    "    return np.random.rand(amount, dim)\n",
    "\n",
    "\n",
    "def get_rand_query(dim):\n",
    "    return np.random.rand(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a62867",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 10**5\n",
    "dim = 5\n",
    "\n",
    "data = init_random(n_points, dim)\n",
    "tree = kdtree(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = init_random(n_points, dim)\n",
    "tree = kdtree(data)\n",
    "query = get_rand_query(dim)\n",
    "\n",
    "neighbors = []\n",
    "kNN_rec(tree, 0, query, neighbors, n_neighbors)\n",
    "\n",
    "# See below\n",
    "brute_force_neighbors = np.array(\n",
    "    list(zip(*brute_force_knn(data, query, n_neighbors)))[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip(*neighbors) will return a list with two elements\n",
    "# The first element is a tuple of all datapoints, the second a tuple of all distances\n",
    "neighbors = np.array(list(zip(*neighbors))[0])\n",
    "\n",
    "# Check if all points are equal\n",
    "np.equal(neighbors, brute_force_neighbors).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9451d4",
   "metadata": {},
   "source": [
    "As we see from above the nearest neighbors from the brute force algorithm and our implementation are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8203b0",
   "metadata": {},
   "source": [
    "### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7474ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [10, 100, 1000, 10000, 100000]\n",
    "# Take 5 queries as in the sheet\n",
    "queries = [get_rand_query(dim) for _ in range(5)]\n",
    "# Since the data is random uniform anyway we dont really have to take a random subset\n",
    "subsets = [data[:size] for size in sizes]\n",
    "trees = [kdtree(subset) for subset in subsets]\n",
    "\n",
    "for query in queries:\n",
    "    visited_counts = []\n",
    "    for tree in trees:\n",
    "        neighbors = []\n",
    "\n",
    "        visited_count = kNN_rec(tree, 0, query, neighbors, n_neighbors=10)\n",
    "        visited_counts.append(visited_count)\n",
    "\n",
    "    plt.plot(\n",
    "        sizes,\n",
    "        visited_counts,\n",
    "        label=f\"query: {query}\",\n",
    "    )\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"number of points\")\n",
    "plt.ylabel(\"nodes visited\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6d45d",
   "metadata": {},
   "source": [
    "### e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b167e",
   "metadata": {},
   "source": [
    "We assume that the task was misspelled and we should repeat the experiment from d)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f59202",
   "metadata": {},
   "source": [
    "From our plots we see that with a higher dimension we visit more nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179031e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 10**5\n",
    "\n",
    "for dim in [1, 3, 5, 10, 20, 30]:\n",
    "    plt.figure(dim)\n",
    "    data = init_random(n_points, dim)\n",
    "\n",
    "    sizes = [10, 100, 1000, 10000, 100000]\n",
    "    # Take 5 queries as in the sheet\n",
    "    queries = [get_rand_query(dim) for _ in range(5)]\n",
    "    # Since the data is random uniform anyway we dont really have to take a random subset\n",
    "    subsets = [data[:size] for size in sizes]\n",
    "    trees = [kdtree(subset) for subset in subsets]\n",
    "\n",
    "    for query in queries:\n",
    "        visited_counts = []\n",
    "        for tree in trees:\n",
    "            neighbors = []\n",
    "\n",
    "            visited_count = kNN_rec(tree, 0, query, neighbors, n_neighbors=10)\n",
    "            visited_counts.append(visited_count)\n",
    "\n",
    "        plt.plot(\n",
    "            sizes,\n",
    "            visited_counts,\n",
    "            label=f\"query: {query}\",\n",
    "        )\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"number of points\")\n",
    "    plt.ylabel(\"nodes visited\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"dimension: {dim}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marten-xps-archlinux",
   "language": "python",
   "name": "marten-xps-archlinux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
