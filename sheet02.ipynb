{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a0836e",
   "metadata": {},
   "source": [
    "# Sheet 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462c2fc",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c6c28",
   "metadata": {},
   "source": [
    "Autors: Marten Ringwelski, Nico Ostermann, Simon Liessem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbbd45",
   "metadata": {},
   "source": [
    "Note that this notebook MUST be executed in order to get everything to work.\n",
    "The tasks can't be run individually. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab973fc",
   "metadata": {},
   "source": [
    "Also eCampus does not allow for uploading nested directory structures which makes it hard to properly organize the files. The files are expected to be in the `data` directory which itself is placed next to this notebook.\n",
    "\n",
    "If you extract the zip file we handed in everything should work just fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b476f10",
   "metadata": {},
   "source": [
    "Autoformatting if `jupyter-black` is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6501019",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import black\n",
    "    import jupyter_black\n",
    "\n",
    "    jupyter_black.load(\n",
    "        lab=False,\n",
    "        line_length=79,\n",
    "        verbosity=\"DEBUG\",\n",
    "        target_version=black.TargetVersion.PY310,\n",
    "    )\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc11336",
   "metadata": {},
   "source": [
    "Import all we weed and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05877eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7116a0c",
   "metadata": {},
   "source": [
    "Set seaborn default theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702c2e1",
   "metadata": {},
   "source": [
    "If needed tweak parameters of matplotlib.\n",
    "Here we increase the size and dpi to bet a bigger but still high-res image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64dba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 200\n",
    "mpl.rcParams[\"figure.figsize\"] = (20, 15)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d8bc9",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b99aa",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae57df",
   "metadata": {},
   "source": [
    "First create the figure and axes.\n",
    "\n",
    "XXX Don't display the plot just jet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151b372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a787d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/values.txt\",\n",
    "    names=[\"data\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4862a5d0",
   "metadata": {},
   "source": [
    "Based on the following kde we assume that the maximum is at about 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd41541",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5558a504",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c56077",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.25\n",
    "colors = [\"orange\", \"green\", \"blue\", \"yellow\"]\n",
    "for adjust, color in zip(np.arange(step, 1 + step, step), colors):\n",
    "    sns.kdeplot(\n",
    "        df,\n",
    "        bw_adjust=adjust,\n",
    "        ax=ax,\n",
    "        label=f\"Adjust = {adjust}\",\n",
    "        # XXX Why doesn't this work?\n",
    "        c=color,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46470b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    df,\n",
    "    binwidth=0.3,\n",
    "    stat=\"density\",\n",
    "    ax=ax,\n",
    "    label=\"Histogram\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d954e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c8b8d",
   "metadata": {},
   "source": [
    "Show the KDE's and a histogram.\n",
    "They all have the same color, which is not intendet.\n",
    "This seems to be a bug in seaborn as specifying a `drawstyle` does not work either.\n",
    "\n",
    "Still despite the colors you can easily distinguish the graphs.\n",
    "We see that with a smaller scale (smaller stdandart derivation) the amount of modes increases to 4 with a scale of 0.25.\n",
    "\n",
    "The histogram shows the same four modes so we suggest that the underlying distribution has 4 modes which are shown in the picture ($x \\in \\{ -0.25, 1, 1.75, 3\\}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bcb37e",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a6e562",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e69cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"data/chronic_kidney_disease_numerical.xls\",\n",
    ")\n",
    "columns = df.columns.tolist()\n",
    "columns.remove(\"class\")\n",
    "df = df.melt(id_vars=[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2785b4",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=m.ceil(len(columns) / 2),\n",
    ")\n",
    "\n",
    "for column, ax in zip(columns, axs.flatten()):\n",
    "    sns.boxplot(\n",
    "        df,\n",
    "        x=df[\"class\"],\n",
    "        y=df[df[\"variable\"] == column][\"value\"],\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xlabel(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec281298",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90373c2f",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/winequality-red.csv\",\n",
    "    sep=\";\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf371415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4b844b",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350cb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1706c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(\n",
    "    column=\"quality\",\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d87a4",
   "metadata": {},
   "source": [
    "From the following plot we see that the minimum quality is 3 and the maximum is 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8a4f4c",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f42fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_quality = df[\"quality\"].min()\n",
    "max_quality = df[\"quality\"].max()\n",
    "# 'Replace the original “quality” column with a new column “quality bin”'\n",
    "# The task is unclrear, we descite to actually replace.\n",
    "df[\"quality\"] = pd.cut(\n",
    "    df[\"quality\"],\n",
    "    bins=[min_quality, min_quality + 1, max_quality - 2, max_quality],\n",
    "    labels=[\"low\", \"medium\", \"high\"],\n",
    "    include_lowest=True,\n",
    "    right=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67dff58",
   "metadata": {},
   "source": [
    "### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a copy here as we modify the category\n",
    "df_wo_medium = df[df[\"quality\"] != \"medium\"].copy()\n",
    "df_wo_medium[\"quality\"] = df_wo_medium[\n",
    "    \"quality\"\n",
    "].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceabb03",
   "metadata": {},
   "source": [
    "### e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3d9f0",
   "metadata": {},
   "source": [
    "The produced plot is really large and for my my browser struggles to display it.\n",
    "A workaround is saving the image to disk and viewing it with a proper image viewer (e.g. imv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12665b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    df_wo_medium,\n",
    "    hue=\"quality\",\n",
    "    diag_kind=\"kde\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5b8afa",
   "metadata": {},
   "source": [
    "### f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97631034",
   "metadata": {},
   "source": [
    "Our approach is do notice differences in the distribution of variables.\n",
    "So critic acid, alcohol, sulphates are obvious choices.\n",
    "For the last two we chose residual sugar and pH because the distributions also differ, but not that much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f5f55",
   "metadata": {},
   "source": [
    "### g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = SelectKBest(\n",
    "    score_func=f_classif,\n",
    "    k=5,\n",
    ").fit(\n",
    "    X=df_wo_medium.drop(columns=\"quality\"),\n",
    "    # Wtf sklearn, why can't you take categorical data?!\n",
    "    y=df_wo_medium[\"quality\"].astype(str),\n",
    ")\n",
    "features = fit.get_feature_names_out().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2199b26",
   "metadata": {},
   "source": [
    "The top five attributes according to F-Score are the same as we chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6619d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kbest = df_wo_medium[features + [\"quality\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59d6eca",
   "metadata": {},
   "source": [
    "### h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e0351",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_grid = sns.PairGrid(\n",
    "    df_kbest,\n",
    "    vars=features,\n",
    "    hue=\"quality\",\n",
    ")\n",
    "pair_grid.map_diag(sns.kdeplot)\n",
    "pair_grid.map_lower(sns.regplot, scatter=False)\n",
    "pair_grid.map_upper(sns.scatterplot)\n",
    "pair_grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f71b50",
   "metadata": {},
   "source": [
    "### i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2738da14",
   "metadata": {},
   "source": [
    "In the figure we can see that sulphates-alcohol and ph-citric acid seem to correlated regardless of quality. Also pH-volatile acidity and citric acid-volatile acidity appear to correlate, but in both cases the values from higher quality wines seem to correlate a bit more. \n",
    "For sulphates-citric acid and sulphates-pH the correlation is dependend on the quality of the wines. In both cases only low quality wines seem to have a high correlation, while the high quality wines have a low correlation.\n",
    "The attribute that seems to have a multimodal distribution is the citric acid. It seems to have a peak at 0 and a peak at 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdf603c",
   "metadata": {},
   "source": [
    "Now let us calculate the outliers programatically.\n",
    "We consider a datapoint an outlier if it is outside 4 times the inter quantile range in any of the given attributes.\n",
    "Suprisingly we get a lot of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr = df_kbest.quantile(\n",
    "    q=0.75,\n",
    "    numeric_only=True,\n",
    ") - df_kbest.quantile(\n",
    "    q=0.25,\n",
    "    numeric_only=True,\n",
    ")\n",
    "median = df_kbest.median(numeric_only=True)\n",
    "lower_bound = median - 2.0 * iqr\n",
    "upper_bound = median + 2.0 * iqr\n",
    "df_kbest_wo_quality = df_kbest.drop(columns=\"quality\")\n",
    "\n",
    "is_outlier = np.logical_or(\n",
    "    df_kbest_wo_quality.le(lower_bound).any(axis=1),\n",
    "    df_kbest_wo_quality.ge(upper_bound).any(axis=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b88a0",
   "metadata": {},
   "source": [
    "Now lets have a look the the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a346549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kbest[is_outlier]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa911ee2",
   "metadata": {},
   "source": [
    "### j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6344e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_consistency(data, by: str, subset: str | list[str] = None):\n",
    "    \"\"\"\n",
    "    Calculate the distance consistency for existing clusters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        The data to use.\n",
    "    by : str\n",
    "        Name of the column whose values define the clusters.\n",
    "    subset: column label or list of column labels, optional\n",
    "        Labels that are considered for the calculation.\n",
    "    \"\"\"\n",
    "    if subset is None:\n",
    "        pass\n",
    "    elif isinstance(subset, str):\n",
    "        data = data[[subset, by]]\n",
    "    elif isinstance(subset, list):\n",
    "        data = data[subset + [by]]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"subset must be an instance of string of list but is {type(subset)}\"\n",
    "        )\n",
    "\n",
    "    groupby_df = data.groupby(by, group_keys=False)\n",
    "    # The index of this df are the groups\n",
    "    centroids = groupby_df.mean()\n",
    "\n",
    "    # This is kind of fancy and hopefully the simplest solution in terms of cognitive overhead and perfomance\n",
    "    # Frist use apply to substract the respective cluster centroid\n",
    "    # Then use apply again to calculate the norm\n",
    "    # As indices are preserved the assigment works fine\n",
    "    # We have to use another dataframe to store the distances as we would otherwise (obiviously) modify\n",
    "    # groupby_df.\n",
    "    distance_df = pd.DataFrame(index=data.index)\n",
    "    distance_df[\"distance\"] = groupby_df.apply(\n",
    "        lambda group: group.drop(columns=by) - centroids.loc[group.name],\n",
    "    ).apply(\n",
    "        np.linalg.norm,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    distance_df[\"min_distance\"] = distance_df[\"distance\"]\n",
    "\n",
    "    # Calculate the nearest centroid distance\n",
    "    for other_group in groupby_df.groups:\n",
    "        other_distance = groupby_df.apply(\n",
    "            lambda group: group.drop(columns=by) - centroids.loc[other_group],\n",
    "        ).apply(\n",
    "            np.linalg.norm,\n",
    "            axis=1,\n",
    "        )\n",
    "        distance_df[\"min_distance\"] = pd.concat(\n",
    "            [distance_df[\"distance\"], other_distance],\n",
    "            axis=1,\n",
    "        ).min(axis=1)\n",
    "\n",
    "    # Count how many points are closest to their own centroid\n",
    "    other_centroid_closer = (\n",
    "        distance_df[\"min_distance\"] < distance_df[\"distance\"]\n",
    "    )\n",
    "    own_centroid_closer_count = other_centroid_closer.value_counts().loc[False]\n",
    "    n_rows = data.shape[0]\n",
    "\n",
    "    return own_centroid_closer_count / n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9924ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0663b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_consistencies = {}\n",
    "\n",
    "for labels in it.combinations(features, 2):\n",
    "    labels = list(labels)\n",
    "    distance_consistencies[\" - \".join(labels)] = distance_consistency(\n",
    "        df_kbest,\n",
    "        by=\"quality\",\n",
    "        subset=labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2afa84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_consistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72caacd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(distance_consistencies, key=distance_consistencies.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9c6aa",
   "metadata": {},
   "source": [
    "From the above we see that the scatterplot of pH against sulphates has the highest distance consistency of roughly 96.42%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e52035",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57043c0e",
   "metadata": {},
   "source": [
    "Obviously a) and b) cite the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889deeb4",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ecd171",
   "metadata": {},
   "source": [
    "The eight variations are the following:\n",
    "1. Embedding scatterplots (SP)\n",
    "\n",
    "Between every pair of variables in the PCP a scatterplot is drawn.\n",
    "The plot is rotated by 45° to share axis.\n",
    "They expect this to improve the visualisation because of the intuitivness of scatterplots.\n",
    "\n",
    "2. Highlighting fuzzy clusters [using color] (Color)\n",
    "\n",
    "They calculate a value (\"enhancement\") $e_i$ for each datapoint $i$.\n",
    "This value correlates to fuzzy clusters and is used for coloring the PCP lines.\n",
    "Color is considered as a strong visual indicator so the autors expect this to improve the visualisation.\n",
    "\n",
    "3. Highlighting fuzzy clusters [using opacity] (Blend)\n",
    "\n",
    "Works exactly like the second variation but the enhancement is used for determining the opacity rather than the colors of the lines.\n",
    "\n",
    "4. Highlighting fuzzy clusters [using color & opacity] (ColorBlend)\n",
    "\n",
    "This method combines the second and the forth method. The enhancement is used for setting the color and opacity.\n",
    "This is expected to improve the the visualisations for the same reasons as the methods Blend and ColorBlend.\n",
    "\n",
    "5. Curves (Curved)\n",
    "\n",
    "This approach is a variation of a common approach called Polylines.\n",
    "In contrast to Polylines in their approach resolves the problem of crossing ambiguity.\n",
    "This should improve the visualistation as a single datapoint can be followed.\n",
    "\n",
    "6.  Random Tour (RT)\n",
    "\n",
    "They animate by generating a random permutation of the data axis and then swapping two axis at a time.\n",
    "When the animation is done the axis are as generated in the random permutation.\n",
    "\n",
    "7. Random Permutation (RP)\n",
    "\n",
    "The idea is the same as in the 6. variation.\n",
    "But the animataion swaps two axis so long that all possible permutations are show trouhout the animation.\n",
    "\n",
    "8. Adding sinus (wobble)\n",
    "\n",
    "This is also an animation based visualisation.\n",
    "The polylines of points that are close together are wobbled by adding a sinus curve (depending on time of the animation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e42d7",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed62f7",
   "metadata": {},
   "source": [
    "The autors expected the vairations to perform in the following order:\n",
    "ColorBlend, Color, SP, Curved, Blend, Wobble, {RT, PT}, Standard\n",
    "\n",
    "Curly braces indicate that the variations in them did not show significant difference in performance.\n",
    "\n",
    "The results did not match the hypothisis.\n",
    "They interpret their results so that the performance is ordered as folows:\n",
    "SP, {Standard, Color, Blend, ColorBlend, Curved, Wobble}, {RT, PT}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c91a1a",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff7dc0",
   "metadata": {},
   "source": [
    "We would use the variation that addidionally draws scatterplots.\n",
    "We base our choice on the result of their studies which showed that this variation was the only one significatly improving the response time of identifying clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
